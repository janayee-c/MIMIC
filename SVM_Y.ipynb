{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test embeddings shape: (2207, 14)\n",
      "Test embeddings shape: (2207, 14)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_cohort = pd.read_csv('cohort_train.csv')\n",
    "train_ids = train_cohort['study_id'].to_list()\n",
    "\n",
    "test_cohort = pd.read_csv('cohort_test.csv')\n",
    "test_ids = test_cohort['study_id'].to_list()\n",
    "\n",
    "# Load embeddings\n",
    "embeddings_df = pd.read_csv('../NLP_processing/embeddings/intense_pneumonia_embeddings/embedded_reports_mean.csv')  \n",
    "\n",
    "\n",
    "embeddings_train = embeddings_df[embeddings_df['study_id'].isin(train_ids)]\n",
    "\n",
    "\n",
    "embeddings_test= embeddings_df[embeddings_df['study_id'].isin(test_ids)]\n",
    "\n",
    "print(f\"Test embeddings shape: {embeddings_train .shape}\")\n",
    "print(f\"Test embeddings shape: {embeddings_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score, roc_auc_score, f1_score, \n",
    "    recall_score, precision_score, confusion_matrix,\n",
    "    classification_report\n",
    ")\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class SVMRadiologyClassifier:\n",
    "    def __init__(self, train_df, test_df, embeddings_train, embeddings_test):\n",
    "        \"\"\"\n",
    "        Initialize the SVM classifier with separate training and test datasets.\n",
    "        \n",
    "        Parameters:\n",
    "            train_df: DataFrame containing the training cohort reports and metadata\n",
    "            test_df: DataFrame containing the test cohort reports and metadata\n",
    "            embeddings_train: Pre-computed embeddings for training cohort\n",
    "            embeddings_test: Pre-computed embeddings for test cohort\n",
    "        \"\"\"\n",
    "        self.train_df = train_df\n",
    "        self.test_df = test_df\n",
    "        \n",
    "        # Convert string embeddings to numpy arrays if needed\n",
    "        self.embeddings_train = np.array([\n",
    "            np.array(ast.literal_eval(emb)) if isinstance(emb, str) else emb \n",
    "            for emb in embeddings_train['embedding']\n",
    "        ])\n",
    "        self.embeddings_test = np.array([\n",
    "            np.array(ast.literal_eval(emb)) if isinstance(emb, str) else emb \n",
    "            for emb in embeddings_test['embedding']\n",
    "        ])\n",
    "        \n",
    "        self.model = None\n",
    "        self.scaler = StandardScaler()\n",
    "        self.misclassified_cases = None\n",
    "        \n",
    "    def prepare_data(self):\n",
    "        \"\"\"\n",
    "        Prepare and scale the data from the separate train and test cohorts.\n",
    "        \"\"\"\n",
    "        # Get labels\n",
    "        y_train = self.train_df['Y'].values\n",
    "        y_test = self.test_df['Y'].values\n",
    "        \n",
    "        # Scale the embeddings\n",
    "        X_train = self.scaler.fit_transform(self.embeddings_train)\n",
    "        X_test = self.scaler.transform(self.embeddings_test)\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test\n",
    "\n",
    "    \n",
    "    \n",
    "    def train_and_evaluate(self, kernel='rbf', C=2.0, probability=True): # made C slightly higher for tighter margin \n",
    "        \"\"\"\n",
    "        Train the SVM model and evaluate its performance on the test set.\n",
    "        Handles different sizes between training and test sets.\n",
    "        \"\"\"\n",
    "        X_train, X_test, y_train, y_test = self.prepare_data()\n",
    "        \n",
    "\n",
    "        self.model = SVC(\n",
    "            kernel=kernel,\n",
    "            C=C,\n",
    "            probability=probability,\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "\n",
    "        self.model.fit(X_train, y_train)\n",
    "    \n",
    "        y_pred = self.model.predict(X_test)\n",
    "        y_pred_proba = self.model.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "\n",
    "        if len(y_test) != len(y_pred):\n",
    "            print(f\"Note: Train set has {len(y_train)} samples, Test set has {len(y_test)} samples\")\n",
    "            y_pred = y_pred[:len(y_test)]\n",
    "            y_pred_proba = y_pred_proba[:len(y_test)]\n",
    "        \n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        \n",
    "        metrics = {\n",
    "            'accuracy': accuracy_score(y_test, y_pred),\n",
    "            'auc': roc_auc_score(y_test, y_pred_proba),\n",
    "            'f1': f1_score(y_test, y_pred),\n",
    "            'sensitivity': tp / (tp + fn),  # True Positive Rate / Recall\n",
    "            'specificity': tn / (tn + fp)   # True Negative Rate\n",
    "        }\n",
    "        \n",
    "        # Examine misclassified\n",
    "        misclassified_mask = y_test != y_pred\n",
    "        self.misclassified_cases = self.test_df[misclassified_mask].copy()\n",
    "        self.misclassified_cases['predicted_label'] = y_pred[misclassified_mask]\n",
    "        self.misclassified_cases['true_label'] = y_test[misclassified_mask]\n",
    "        self.misclassified_cases['prediction_probability'] = y_pred_proba[misclassified_mask]\n",
    "    \n",
    "        return metrics\n",
    "\n",
    "    \n",
    "    def analyze_misclassified_cases(self):\n",
    "        \"\"\"\n",
    "        Analyze cases where the model made mistakes.\n",
    "        \"\"\"\n",
    "        if self.misclassified_cases is None:\n",
    "            print(\"Please run train_and_evaluate first.\")\n",
    "            return\n",
    "        \n",
    "        print(\"\\nAnalysis of Misclassified Cases:\")\n",
    "        print(f\"Total misclassified cases: {len(self.misclassified_cases)}\")\n",
    "        \n",
    "        # Analyze false positives and negatives\n",
    "        false_positives = self.misclassified_cases[\n",
    "            (self.misclassified_cases['predicted_label'] == 1) & \n",
    "            (self.misclassified_cases['true_label'] == 0)\n",
    "        ]\n",
    "        \n",
    "        false_negatives = self.misclassified_cases[\n",
    "            (self.misclassified_cases['predicted_label'] == 0) & \n",
    "            (self.misclassified_cases['true_label'] == 1)\n",
    "        ]\n",
    "        \n",
    "        print(f\"\\nFalse Positives: {len(false_positives)} cases\")\n",
    "        print(f\"False Negatives: {len(false_negatives)} cases\")\n",
    "        \n",
    "        # Display example cases\n",
    "        def display_cases(cases, case_type, n=5):\n",
    "            print(f\"\\nExample {case_type} (showing {min(n, len(cases))} cases):\")\n",
    "            for _, case in cases.head(n).iterrows():\n",
    "                print(f\"\\nStudy ID: {case['study_id']}\")\n",
    "                print(f\"Confidence: {case['prediction_probability']:.3f}\")\n",
    "                print(\"-\" * 80)\n",
    "        \n",
    "        display_cases(false_positives, \"False Positives\")\n",
    "        display_cases(false_negatives, \"False Negatives\")\n",
    "        \n",
    "        return false_positives, false_negatives\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to run the SVM classification pipeline.\n",
    "    \"\"\"\n",
    "    # Run Classifier\n",
    "    classifier = SVMRadiologyClassifier(\n",
    "        train_cohort, \n",
    "        test_cohort, \n",
    "        embeddings_train, \n",
    "        embeddings_test\n",
    "    )\n",
    "    \n",
    "    # Train and evaluate with different kernel options\n",
    "    kernels = ['rbf', 'linear']\n",
    "    best_metrics = None\n",
    "    best_kernel = None\n",
    "    \n",
    "    for kernel in kernels:\n",
    "        print(f\"\\nTraining with {kernel} kernel:\")\n",
    "        metrics = classifier.train_and_evaluate(kernel=kernel)\n",
    "        \n",
    "        print(\"\\nModel Performance Metrics:\")\n",
    "        print(f\"Accuracy: {metrics['accuracy']:.4f}\")\n",
    "        print(f\"AUC-ROC: {metrics['auc']:.4f}\")\n",
    "        print(f\"F1 Score: {metrics['f1']:.4f}\")\n",
    "        print(f\"Sensitivity: {metrics['sensitivity']:.4f}\")\n",
    "        \n",
    "        if best_metrics is None or metrics['auc'] > best_metrics['auc']:\n",
    "            best_metrics = metrics\n",
    "            best_kernel = kernel\n",
    "    \n",
    "    print(f\"\\nBest performing kernel: {best_kernel}\")\n",
    "    \n",
    "    false_positives, false_negatives = classifier.analyze_misclassified_cases()\n",
    "    return classifier, best_metrics, (false_positives, false_negatives)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with rbf kernel:\n",
      "Note: Train set has 2207 samples, Test set has 552 samples\n",
      "\n",
      "Model Performance Metrics:\n",
      "Accuracy: 0.7065\n",
      "AUC-ROC: 0.5236\n",
      "F1 Score: 0.1649\n",
      "Sensitivity: 0.1143\n",
      "\n",
      "Training with linear kernel:\n",
      "Note: Train set has 2207 samples, Test set has 552 samples\n",
      "\n",
      "Model Performance Metrics:\n",
      "Accuracy: 0.6486\n",
      "AUC-ROC: 0.4935\n",
      "F1 Score: 0.1917\n",
      "Sensitivity: 0.1643\n",
      "\n",
      "Best performing kernel: rbf\n",
      "\n",
      "Analysis of Misclassified Cases:\n",
      "Total misclassified cases: 194\n",
      "\n",
      "False Positives: 77 cases\n",
      "False Negatives: 117 cases\n",
      "\n",
      "Example False Positives (showing 5 cases):\n",
      "\n",
      "Study ID: 58561179\n",
      "Confidence: 0.241\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Study ID: 59450170\n",
      "Confidence: 0.248\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Study ID: 50964535\n",
      "Confidence: 0.243\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Study ID: 55766889\n",
      "Confidence: 0.245\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Study ID: 57696885\n",
      "Confidence: 0.243\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Example False Negatives (showing 5 cases):\n",
      "\n",
      "Study ID: 56822947\n",
      "Confidence: 0.236\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Study ID: 54589936\n",
      "Confidence: 0.226\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Study ID: 51971980\n",
      "Confidence: 0.234\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Study ID: 55976769\n",
      "Confidence: 0.215\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Study ID: 50078440\n",
      "Confidence: 0.233\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# loading XGBOOST Prediction Learning Data \n",
    "classifier, metrics, error_analysis = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(self, kernel='rbf', C=1.0, probability=True):\n",
    "    \"\"\"\n",
    "    Train the SVM model and evaluate its performance on the test set.\n",
    "    Handles different sizes between training and test sets.\n",
    "    \"\"\"\n",
    "    X_train, X_test, y_train, y_test = self.prepare_data()\n",
    "    \n",
    "    # Initialize and train SVM model\n",
    "    self.model = SVC(\n",
    "        kernel=kernel,\n",
    "        C=C,\n",
    "        probability=probability,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    self.model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on test set\n",
    "    y_pred = self.model.predict(X_test)\n",
    "    y_pred_proba = self.model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Ensure predictions align with test labels\n",
    "    if len(y_test) != len(y_pred):\n",
    "        print(f\"Note: Train set has {len(y_train)} samples, Test set has {len(y_test)} samples\")\n",
    "        y_pred = y_pred[:len(y_test)]\n",
    "        y_pred_proba = y_pred_proba[:len(y_test)]\n",
    "    \n",
    "    # Calculate confusion matrix for sensitivity calculation\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    \n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'auc': roc_auc_score(y_test, y_pred_proba),\n",
    "        'f1': f1_score(y_test, y_pred),\n",
    "        'sensitivity': tp / (tp + fn),  # True Positive Rate / Recall\n",
    "        'specificity': tn / (tn + fp)   # True Negative Rate\n",
    "    }\n",
    "    \n",
    "    # Store misclassified cases\n",
    "    misclassified_mask = y_test != y_pred\n",
    "    self.misclassified_cases = self.test_df[misclassified_mask].copy()\n",
    "    self.misclassified_cases['predicted_label'] = y_pred[misclassified_mask]\n",
    "    self.misclassified_cases['true_label'] = y_test[misclassified_mask]\n",
    "    self.misclassified_cases['prediction_probability'] = y_pred_proba[misclassified_mask]\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to run the SVM classification pipeline.\n",
    "    \"\"\"\n",
    "    # Initialize and run the classifier\n",
    "    classifier = SVMRadiologyClassifier(\n",
    "        train_cohort, \n",
    "        test_cohort, \n",
    "        embeddings_train, \n",
    "        embeddings_test\n",
    "    )\n",
    "    \n",
    "    # Train and evaluate with different kernel options\n",
    "    kernels = ['rbf', 'linear']\n",
    "    best_metrics = None\n",
    "    best_kernel = None\n",
    "    \n",
    "    for kernel in kernels:\n",
    "        print(f\"\\nTraining with {kernel} kernel:\")\n",
    "        metrics = classifier.train_and_evaluate(kernel=kernel)\n",
    "        \n",
    "        print(\"\\nModel Performance Metrics:\")\n",
    "        print(f\"Accuracy: {metrics['accuracy']:.4f}\")\n",
    "        print(f\"AUC-ROC: {metrics['auc']:.4f}\")\n",
    "        print(f\"F1 Score: {metrics['f1']:.4f}\")\n",
    "        print(f\"Sensitivity: {metrics['sensitivity']:.4f}\")\n",
    "        print(f\"Specificity: {metrics['specificity']:.4f}\")\n",
    "        \n",
    "        if best_metrics is None or metrics['auc'] > best_metrics['auc']:\n",
    "            best_metrics = metrics\n",
    "            best_kernel = kernel\n",
    "    \n",
    "    print(f\"\\nBest performing kernel: {best_kernel}\")\n",
    "    \n",
    "    false_positives, false_negatives = classifier.analyze_misclassified_cases()\n",
    "    return classifier, best_metrics, (false_positives, false_negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "    def train_and_evaluate(self, kernel='rbf', C=1.0, probability=True):\n",
    "        \"\"\"\n",
    "        Train the SVM model and evaluate its performance on the test set.\n",
    "        Handles different sizes between training and test sets.\n",
    "        \"\"\"\n",
    "        X_train, X_test, y_train, y_test = self.prepare_data()\n",
    "        \n",
    "        # Initialize and train SVM model\n",
    "        self.model = SVC(\n",
    "            kernel=kernel,\n",
    "            C=C,\n",
    "            probability=probability,\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        # Train the model\n",
    "        self.model.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions on test set\n",
    "        y_pred = self.model.predict(X_test)\n",
    "        y_pred_proba = self.model.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        # Ensure predictions align with test labels\n",
    "        if len(y_test) != len(y_pred):\n",
    "            print(f\"Note: Train set has {len(y_train)} samples, Test set has {len(y_test)} samples\")\n",
    "            y_pred = y_pred[:len(y_test)]\n",
    "            y_pred_proba = y_pred_proba[:len(y_test)]\n",
    "        \n",
    "        metrics = {\n",
    "            'accuracy': accuracy_score(y_test, y_pred),\n",
    "            'auc': roc_auc_score(y_test, y_pred_proba),\n",
    "            'f1': f1_score(y_test, y_pred)\n",
    "            'sensitivity': recall_score(y_true, y_pred),  # Same as recall\n",
    "        }\n",
    "        \n",
    "        # make sure we store the misclassified cases\n",
    "        misclassified_mask = y_test != y_pred\n",
    "        self.misclassified_cases = self.test_df[misclassified_mask].copy()\n",
    "        self.misclassified_cases['predicted_label'] = y_pred[misclassified_mask]\n",
    "        self.misclassified_cases['true_label'] = y_test[misclassified_mask]\n",
    "        self.misclassified_cases['prediction_probability'] = y_pred_proba[misclassified_mask]\n",
    "        \n",
    "        return metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
