{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERTopic - Pneumonia Other Types "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from umap import UMAP\n",
    "import pandas as pd \n",
    "from hdbscan import HDBSCAN\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from bertopic import BERTopic\n",
    "from bertopic.representation import KeyBERTInspired\n",
    "from bertopic.vectorizers import ClassTfidfTransformer\n",
    "from bertopic.representation import MaximalMarginalRelevance\n",
    "import torch\n",
    "import os\n",
    "import numpy as np \n",
    "import ast\n",
    "\n",
    "# Ensure 'embeddings' column is treated as a list of floats\n",
    "def convert_to_array(embedding_str):\n",
    "    try:\n",
    "        return np.array(ast.literal_eval(embedding_str), dtype=np.float32)\n",
    "    except (ValueError, SyntaxError):\n",
    "        return None  # Return None for rows with invalid embeddings\n",
    "\n",
    "# Read the DataFrame\n",
    "pneumonia_type_df = pd.read_csv('../NER_embeddings/bacterial/radgraph_with_embeddings.csv')\n",
    "\n",
    "# Filter the dataset to keep only bacterial pneumonia cases\n",
    "bacterial_df = pneumonia_type_df[pneumonia_type_df['pneumonia_type'] == 'bacterial'].copy()\n",
    "\n",
    "# Drop rows where 'radgraph_text' is NaN or empty\n",
    "bacterial_df = bacterial_df[bacterial_df['radgraph_text'].notna()]\n",
    "bacterial_df = bacterial_df[bacterial_df['radgraph_text'].str.strip() != '']\n",
    "\n",
    "def convert_to_array(embedding_str):\n",
    "    try:\n",
    "        return np.array(ast.literal_eval(embedding_str), dtype=np.float32)\n",
    "    except (ValueError, SyntaxError):\n",
    "        return None  # Return None for rows with invalid embeddings\n",
    "\n",
    "bacterial_df['embedding'] = bacterial_df['embedding'].apply(convert_to_array)\n",
    "\n",
    "# Drop rows where embeddings couldn't be converted\n",
    "bacterial_df = bacterial_df.dropna(subset=['embedding'])\n",
    "\n",
    "# Extract documents and embeddings\n",
    "docs = bacterial_df['radgraph_text'].astype(str).tolist()\n",
    "embeddings = np.vstack(bacterial_df['embedding'].values)\n",
    "# Ensure embeddings shape is correct\n",
    "print(f\"Embeddings shape: {embeddings.shape}\")  # Should be (num_docs, embedding_dim)\n",
    "\n",
    "# Ensure shape consistency\n",
    "assert len(docs) == embeddings.shape[0], \"Mismatch between docs and embeddings!\"\n",
    "print(f\"Filtered dataset size: {len(docs)}\")\n",
    "\n",
    "\n",
    "# Load the previously saved CXR model\n",
    "model_path = \"../../models/RADGRAPH_embeddings/bacterial\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "embedding_model = AutoModel.from_pretrained(model_path)\n",
    "\n",
    "\n",
    "# UMAP model for dimensionality reduction\n",
    "umap_model = UMAP(n_neighbors=30, n_components=5, min_dist=0.0, metric='cosine')\n",
    "\n",
    "# HDBSCAN model for clustering\n",
    "hdbscan_model = HDBSCAN(min_samples=20, \n",
    "                        gen_min_span_tree=True, \n",
    "                        prediction_data=True, \n",
    "                        min_cluster_size=5, \n",
    "                        metric='euclidean', \n",
    "                        cluster_selection_method='leaf')\n",
    "\n",
    "# Create the CountVectorizer instance with the custom LemmaTokenizer\n",
    "vectorizer_model = CountVectorizer(strip_accents='unicode', \n",
    "                                   stop_words='english', \n",
    "                                   ngram_range=(1, 3), \n",
    "                                   max_df=0.6) # remove general terms \n",
    "                                \n",
    "\n",
    "# Step 1: Initialize custom c-TF-IDF model\n",
    "ctfidf_model = ClassTfidfTransformer(\n",
    "    bm25_weighting=False,             # BM25: Beyond a certain point, additional occurrences of a term donâ€™t contribute as much to its weight, introducing a saturation effect. This is controlled by the k1 parameter.\n",
    "    reduce_frequent_words=True,       # Reduce the impact of overly frequent words (True if needed)\n",
    ")\n",
    "\n",
    "\n",
    "# chain model: first extract the most relevant with KeyBERT, then prioritize diversity \n",
    "representation_model = [KeyBERTInspired(top_n_words=30, random_state=42), MaximalMarginalRelevance(diversity=0.7)]\n",
    "\n",
    "# Initialize and fit BERTopic with probability calculation\n",
    "topic_model = BERTopic(\n",
    "    embedding_model=embedding_model,\n",
    "    umap_model=umap_model,\n",
    "    hdbscan_model=hdbscan_model,\n",
    "    ctfidf_model=ctfidf_model, \n",
    "    vectorizer_model=vectorizer_model,\n",
    "    verbose=True,\n",
    "    representation_model=representation_model,\n",
    "    top_n_words=10,\n",
    "    calculate_probabilities=True,  # Ensure that BERTopic calculates probabilities\n",
    ")\n",
    "\n",
    "# Fit the model with documents and embeddings\n",
    "# probabilities \n",
    "topics, probabilities = topic_model.fit_transform(docs, embeddings=embeddings)\n",
    "\n",
    "# Create the directory if it does not exist\n",
    "os.makedirs('../../models/BERTopic_Bacterial', exist_ok=True)\n",
    "os.makedirs('../../models/BERTopic_Bacterial/representations/', exist_ok=True)\n",
    "os.makedirs('../../models/BERTopic_Bacterial/clusters/', exist_ok=True)\n",
    "\n",
    "# Save the BERTopic model for later use as a directory \n",
    "# Save the ctf-idf matrix  for terms \n",
    "topic_model.save(\"../../models/BERTopic_Bacterial/representations/specter_representation_keybert_mmr\", serialization=\"pytorch\", save_ctfidf=True)\n",
    "\n",
    "# Get HDBSCAN cluster labels and probabilities\n",
    "hdbscan_labels = topic_model.hdbscan_model.labels_\n",
    "#The prediction_data=True enables the model to calculate probabilities by predicting how confidently each document fits into a cluster (fits and transforms)\n",
    "hdbscan_probabilities = topic_model.hdbscan_model.probabilities_ # These probabilities tell you how confidently HDBSCAN assigns a document to its cluster (after fitting embeddings according to hdb model)\n",
    "\n",
    "# Save HDBSCAN cluster labels and probabilities\n",
    "torch.save(hdbscan_labels, '../../models/BERTopic_Bacterial/clusters/hdbscan_labels_keybert_mmr.pt')\n",
    "torch.save(hdbscan_probabilities, '../../models/BERTopic_Bacterial/clusters/hdbscan_probabilities_keybert_mmr.pt')\n",
    "\n",
    "## Manually save some files to the model directory \n",
    "# Save BERTopic probabilities (topic-patent / document-topic matrix) inside the model directory\n",
    "torch.save(probabilities, '../../models/BERTopic_Bacterial/representations/specter_representation_keybert_mmr/specter_probabilities_keybert_mmr.pt') # the actual document-topic probabilities that delineate association of each document to topic(s)\n",
    "\n",
    "# Print the topic information after applying custom c-TF-IDF\n",
    "topic_info = topic_model.get_topic_info()\n",
    "torch.save(topic_info, '../../models/BERTopic_Bacterial/representations/specter_representation_keybert_mmr/topic_info_keybert_mmr.pt')\n",
    "topic_info.to_csv('../../models/BERTopic_Bacterial/representations/specter_representation_keybert_mmr/topic_info.csv')\n",
    "topic_info.to_excel('../../models/BERTopic_Bacterial/representations/specter_representation_keybert_mmr/topic_info.xlsx')\n",
    "\n",
    "# Save the representation and count vectorizer models to a .pt file\n",
    "torch.save(representation_model, '../../models/BERTopic_Bacterial/representations/specter_representation_keybert_mmr/representation_model.pt')\n",
    "torch.save(vectorizer_model, '../../models/BERTopic_Bacterial/representations/specter_representation_keybert_mmr/vectorizer_model.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
