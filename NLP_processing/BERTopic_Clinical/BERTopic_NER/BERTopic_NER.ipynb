{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Designated for Generating BERTopic Embeddings from NER "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Radgraph Entities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gd/p6nf_1w11938t89t0bj2r9lc0000gn/T/ipykernel_98904/2697874972.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  radgraph_tensor = torch.load(tensor_radgraph_path) # already a df\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'0': {'text': 'cardiac silhouette size is normal . mediastinal and hilar contours are unremarkable . the pulmonary vasculature is normal . ill - defined parenchymal opacities are noted bilaterally , most pronounced within both lung bases , concerning for multifocal pneumonia . no pleural effusion or pneumothorax is present . there are no acute osseous abnormalities . findings concerning for multifocal pneumonia . followup radiographs after treatment are recommended to ensure resolution of this finding .',\n",
       "  'entities': {'1': {'tokens': 'cardiac',\n",
       "    'label': 'Anatomy::definitely present',\n",
       "    'start_ix': 0,\n",
       "    'end_ix': 0,\n",
       "    'relations': []},\n",
       "   '2': {'tokens': 'silhouette',\n",
       "    'label': 'Anatomy::definitely present',\n",
       "    'start_ix': 1,\n",
       "    'end_ix': 1,\n",
       "    'relations': [['modify', '1']]},\n",
       "   '3': {'tokens': 'size',\n",
       "    'label': 'Anatomy::definitely present',\n",
       "    'start_ix': 2,\n",
       "    'end_ix': 2,\n",
       "    'relations': [['modify', '1']]},\n",
       "   '4': {'tokens': 'normal',\n",
       "    'label': 'Observation::definitely present',\n",
       "    'start_ix': 4,\n",
       "    'end_ix': 4,\n",
       "    'relations': [['located_at', '1']]},\n",
       "   '5': {'tokens': 'mediastinal',\n",
       "    'label': 'Anatomy::definitely present',\n",
       "    'start_ix': 6,\n",
       "    'end_ix': 6,\n",
       "    'relations': []},\n",
       "   '6': {'tokens': 'hilar',\n",
       "    'label': 'Anatomy::definitely present',\n",
       "    'start_ix': 8,\n",
       "    'end_ix': 8,\n",
       "    'relations': []},\n",
       "   '7': {'tokens': 'contours',\n",
       "    'label': 'Anatomy::definitely present',\n",
       "    'start_ix': 9,\n",
       "    'end_ix': 9,\n",
       "    'relations': [['modify', '5'], ['modify', '6']]},\n",
       "   '8': {'tokens': 'unremarkable',\n",
       "    'label': 'Observation::definitely present',\n",
       "    'start_ix': 11,\n",
       "    'end_ix': 11,\n",
       "    'relations': [['located_at', '5'], ['located_at', '6']]},\n",
       "   '9': {'tokens': 'pulmonary',\n",
       "    'label': 'Anatomy::definitely present',\n",
       "    'start_ix': 14,\n",
       "    'end_ix': 14,\n",
       "    'relations': [['modify', '10']]},\n",
       "   '10': {'tokens': 'vasculature',\n",
       "    'label': 'Anatomy::definitely present',\n",
       "    'start_ix': 15,\n",
       "    'end_ix': 15,\n",
       "    'relations': []},\n",
       "   '11': {'tokens': 'normal',\n",
       "    'label': 'Observation::definitely present',\n",
       "    'start_ix': 17,\n",
       "    'end_ix': 17,\n",
       "    'relations': [['located_at', '10']]},\n",
       "   '12': {'tokens': 'ill - defined',\n",
       "    'label': 'Observation::definitely present',\n",
       "    'start_ix': 19,\n",
       "    'end_ix': 21,\n",
       "    'relations': [['modify', '14']]},\n",
       "   '13': {'tokens': 'parenchymal',\n",
       "    'label': 'Anatomy::definitely present',\n",
       "    'start_ix': 22,\n",
       "    'end_ix': 22,\n",
       "    'relations': []},\n",
       "   '14': {'tokens': 'opacities',\n",
       "    'label': 'Observation::definitely present',\n",
       "    'start_ix': 23,\n",
       "    'end_ix': 23,\n",
       "    'relations': [['located_at', '13'],\n",
       "     ['located_at', '18'],\n",
       "     ['suggestive_of', '21']]},\n",
       "   '15': {'tokens': 'bilaterally',\n",
       "    'label': 'Anatomy::definitely present',\n",
       "    'start_ix': 26,\n",
       "    'end_ix': 26,\n",
       "    'relations': [['modify', '13']]},\n",
       "   '16': {'tokens': 'pronounced',\n",
       "    'label': 'Observation::definitely present',\n",
       "    'start_ix': 29,\n",
       "    'end_ix': 29,\n",
       "    'relations': []},\n",
       "   '17': {'tokens': 'both',\n",
       "    'label': 'Anatomy::definitely present',\n",
       "    'start_ix': 31,\n",
       "    'end_ix': 31,\n",
       "    'relations': [['modify', '18']]},\n",
       "   '18': {'tokens': 'lung',\n",
       "    'label': 'Anatomy::definitely present',\n",
       "    'start_ix': 32,\n",
       "    'end_ix': 32,\n",
       "    'relations': []},\n",
       "   '19': {'tokens': 'bases',\n",
       "    'label': 'Anatomy::definitely present',\n",
       "    'start_ix': 33,\n",
       "    'end_ix': 33,\n",
       "    'relations': [['modify', '18']]},\n",
       "   '20': {'tokens': 'multifocal',\n",
       "    'label': 'Observation::definitely present',\n",
       "    'start_ix': 37,\n",
       "    'end_ix': 37,\n",
       "    'relations': [['modify', '21']]},\n",
       "   '21': {'tokens': 'pneumonia',\n",
       "    'label': 'Observation::definitely present',\n",
       "    'start_ix': 38,\n",
       "    'end_ix': 38,\n",
       "    'relations': []},\n",
       "   '22': {'tokens': 'pleural',\n",
       "    'label': 'Anatomy::definitely present',\n",
       "    'start_ix': 41,\n",
       "    'end_ix': 41,\n",
       "    'relations': []},\n",
       "   '23': {'tokens': 'effusion',\n",
       "    'label': 'Observation::definitely absent',\n",
       "    'start_ix': 42,\n",
       "    'end_ix': 42,\n",
       "    'relations': [['located_at', '22']]},\n",
       "   '24': {'tokens': 'pneumothorax',\n",
       "    'label': 'Observation::definitely absent',\n",
       "    'start_ix': 44,\n",
       "    'end_ix': 44,\n",
       "    'relations': []},\n",
       "   '25': {'tokens': 'acute',\n",
       "    'label': 'Observation::definitely absent',\n",
       "    'start_ix': 51,\n",
       "    'end_ix': 51,\n",
       "    'relations': [['modify', '27']]},\n",
       "   '26': {'tokens': 'osseous',\n",
       "    'label': 'Anatomy::definitely present',\n",
       "    'start_ix': 52,\n",
       "    'end_ix': 52,\n",
       "    'relations': []},\n",
       "   '27': {'tokens': 'abnormalities',\n",
       "    'label': 'Observation::definitely absent',\n",
       "    'start_ix': 53,\n",
       "    'end_ix': 53,\n",
       "    'relations': [['located_at', '26']]},\n",
       "   '28': {'tokens': 'multifocal',\n",
       "    'label': 'Observation::definitely present',\n",
       "    'start_ix': 58,\n",
       "    'end_ix': 58,\n",
       "    'relations': [['modify', '29']]},\n",
       "   '29': {'tokens': 'pneumonia',\n",
       "    'label': 'Observation::definitely present',\n",
       "    'start_ix': 59,\n",
       "    'end_ix': 59,\n",
       "    'relations': []}},\n",
       "  'data_source': None,\n",
       "  'data_split': 'inference'}}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "import pandas as pd \n",
    "\n",
    "csv_radgraph_path = \"../../NER/ner_database.csv\"\n",
    "tensor_radgraph_path = \"../../NER/ner_database.pt\"\n",
    "\n",
    "radgraph_tensor = torch.load(tensor_radgraph_path) # already a df \n",
    "sample = radgraph_tensor.iloc[0]['extracts']\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_id</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>report_path</th>\n",
       "      <th>full_text</th>\n",
       "      <th>examination</th>\n",
       "      <th>indication</th>\n",
       "      <th>technique</th>\n",
       "      <th>comparison</th>\n",
       "      <th>findings</th>\n",
       "      <th>impression</th>\n",
       "      <th>has_comparison</th>\n",
       "      <th>report_length</th>\n",
       "      <th>radgraph_text</th>\n",
       "      <th>extracts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57106576</td>\n",
       "      <td>18110461</td>\n",
       "      <td>../data/files/p18/p18110461/s57106576.txt</td>\n",
       "      <td>FINAL REPORT EXAMINATION: CHEST (PA AND LAT) I...</td>\n",
       "      <td>chest (pa and lat)</td>\n",
       "      <td>history: [REMOVED]f with cough</td>\n",
       "      <td>chest pa and lateral</td>\n",
       "      <td>[REMOVED]</td>\n",
       "      <td>cardiac silhouette size is normal. mediastinal...</td>\n",
       "      <td>findings concerning for multifocal pneumonia. ...</td>\n",
       "      <td>True</td>\n",
       "      <td>645</td>\n",
       "      <td>cardiac silhouette size is normal. mediastinal...</td>\n",
       "      <td>{'0': {'text': 'cardiac silhouette size is nor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52444794</td>\n",
       "      <td>15447063</td>\n",
       "      <td>../data/files/p15/p15447063/s52444794.txt</td>\n",
       "      <td>FINAL REPORT INDICATION: History of left-sided...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>history of left-sided weakness for 12 hours. p...</td>\n",
       "      <td>ap and lateral radiographs of the chest.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mild cardiomegaly has been stable compared to ...</td>\n",
       "      <td>interval increase in consolidation at the left...</td>\n",
       "      <td>False</td>\n",
       "      <td>806</td>\n",
       "      <td>mild cardiomegaly has been stable compared to ...</td>\n",
       "      <td>{'0': {'text': 'mild cardiomegaly has been sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>58791719</td>\n",
       "      <td>13243522</td>\n",
       "      <td>../data/files/p13/p13243522/s58791719.txt</td>\n",
       "      <td>FINAL REPORT EXAMINATION: Chest radiograph IND...</td>\n",
       "      <td>chest radiograph</td>\n",
       "      <td>[REMOVED]m with cystic fibrosis and fever/coug...</td>\n",
       "      <td>frontal and lateral view.</td>\n",
       "      <td>comparison is made to multiple chest radiograp...</td>\n",
       "      <td>right chest wall port-a-cath ends at the cavoa...</td>\n",
       "      <td>chronic changes of cystic fibrosis as describe...</td>\n",
       "      <td>True</td>\n",
       "      <td>1136</td>\n",
       "      <td>right chest wall port-a-cath ends at the cavoa...</td>\n",
       "      <td>{'0': {'text': 'right chest wall port - a - ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51779043</td>\n",
       "      <td>11423061</td>\n",
       "      <td>../data/files/p11/p11423061/s51779043.txt</td>\n",
       "      <td>FINAL REPORT HISTORY: Chest pain. TECHNIQUE: U...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>upright ap view of the chest.</td>\n",
       "      <td>[REMOVED].</td>\n",
       "      <td>low lung volumes limit assessment of the lung ...</td>\n",
       "      <td>low lung volumes limit assessment of the lung ...</td>\n",
       "      <td>True</td>\n",
       "      <td>685</td>\n",
       "      <td>low lung volumes limit assessment of the lung ...</td>\n",
       "      <td>{'0': {'text': 'low lung volumes limit assessm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>58785779</td>\n",
       "      <td>15379716</td>\n",
       "      <td>../data/files/p15/p15379716/s58785779.txt</td>\n",
       "      <td>FINAL REPORT INDICATION: Pneumonia, cough, and...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pneumonia, cough, and shortness of breath.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chest radiograph from [REMOVED] and chest ct f...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>stable lingular and increased right middle lob...</td>\n",
       "      <td>True</td>\n",
       "      <td>600</td>\n",
       "      <td>nan</td>\n",
       "      <td>{'0': {'text': 'nan', 'entities': {}, 'data_so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2754</th>\n",
       "      <td>58255867</td>\n",
       "      <td>14236258</td>\n",
       "      <td>../data/files/p14/p14236258/s58255867.txt</td>\n",
       "      <td>FINAL REPORT INDICATION: [REMOVED]M with cough...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[REMOVED]m with cough // r/o pna</td>\n",
       "      <td>ap and lateral views of the chest.</td>\n",
       "      <td>[REMOVED]. [REMOVED] and ct torso from [REMOVED].</td>\n",
       "      <td>vague opacity projecting over the right mid/lo...</td>\n",
       "      <td>vague right mid/lower opacity, nonspecific the...</td>\n",
       "      <td>True</td>\n",
       "      <td>695</td>\n",
       "      <td>vague opacity projecting over the right mid/lo...</td>\n",
       "      <td>{'0': {'text': 'vague opacity projecting over ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2755</th>\n",
       "      <td>59289169</td>\n",
       "      <td>10623647</td>\n",
       "      <td>../data/files/p10/p10623647/s59289169.txt</td>\n",
       "      <td>WET READ: [REMOVED] [REMOVED] [REMOVED] 4:26 P...</td>\n",
       "      <td>chest: frontal and lateral views</td>\n",
       "      <td>history: [REMOVED]m with hypoxia // pna?</td>\n",
       "      <td>chest: frontal and lateral</td>\n",
       "      <td>[REMOVED]</td>\n",
       "      <td>bilateral patchy pulmonary opacities appear sl...</td>\n",
       "      <td>patchy bilateral mid to lower lung opacities a...</td>\n",
       "      <td>True</td>\n",
       "      <td>1760</td>\n",
       "      <td>bilateral patchy pulmonary opacities appear sl...</td>\n",
       "      <td>{'0': {'text': 'bilateral patchy pulmonary opa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2756</th>\n",
       "      <td>55182265</td>\n",
       "      <td>15116068</td>\n",
       "      <td>../data/files/p15/p15116068/s55182265.txt</td>\n",
       "      <td>WET READ: [REMOVED] [REMOVED] [REMOVED] 11:56 ...</td>\n",
       "      <td>chest radiograph.</td>\n",
       "      <td>[REMOVED]f with cough, fever, sob // ? pna</td>\n",
       "      <td>single portable semi upright radiograph the ch...</td>\n",
       "      <td>chest ct: [REMOVED], [REMOVED]</td>\n",
       "      <td>extensive bronchiectasis is again noted in the...</td>\n",
       "      <td>extensive bilateral bronchiectasis, with super...</td>\n",
       "      <td>True</td>\n",
       "      <td>1100</td>\n",
       "      <td>extensive bronchiectasis is again noted in the...</td>\n",
       "      <td>{'0': {'text': 'extensive bronchiectasis is ag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2757</th>\n",
       "      <td>50696726</td>\n",
       "      <td>17025867</td>\n",
       "      <td>../data/files/p17/p17025867/s50696726.txt</td>\n",
       "      <td>FINAL REPORT INDICATION: Cough and weakness. C...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cough and weakness.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>radiograph available from [REMOVED]. frontal a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1. increase in density of a right lower and mi...</td>\n",
       "      <td>True</td>\n",
       "      <td>649</td>\n",
       "      <td>nan</td>\n",
       "      <td>{'0': {'text': 'nan', 'entities': {}, 'data_so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2758</th>\n",
       "      <td>58035940</td>\n",
       "      <td>13478841</td>\n",
       "      <td>../data/files/p13/p13478841/s58035940.txt</td>\n",
       "      <td>FINAL REPORT CHEST, TWO VIEWS, [REMOVED]. HIST...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ap and lateral views of the chest are compared...</td>\n",
       "      <td>no definite acute cardiopulmonary process base...</td>\n",
       "      <td>False</td>\n",
       "      <td>550</td>\n",
       "      <td>ap and lateral views of the chest are compared...</td>\n",
       "      <td>{'0': {'text': 'ap and lateral views of the ch...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2759 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      study_id  subject_id                                report_path  \\\n",
       "0     57106576    18110461  ../data/files/p18/p18110461/s57106576.txt   \n",
       "1     52444794    15447063  ../data/files/p15/p15447063/s52444794.txt   \n",
       "2     58791719    13243522  ../data/files/p13/p13243522/s58791719.txt   \n",
       "3     51779043    11423061  ../data/files/p11/p11423061/s51779043.txt   \n",
       "4     58785779    15379716  ../data/files/p15/p15379716/s58785779.txt   \n",
       "...        ...         ...                                        ...   \n",
       "2754  58255867    14236258  ../data/files/p14/p14236258/s58255867.txt   \n",
       "2755  59289169    10623647  ../data/files/p10/p10623647/s59289169.txt   \n",
       "2756  55182265    15116068  ../data/files/p15/p15116068/s55182265.txt   \n",
       "2757  50696726    17025867  ../data/files/p17/p17025867/s50696726.txt   \n",
       "2758  58035940    13478841  ../data/files/p13/p13478841/s58035940.txt   \n",
       "\n",
       "                                              full_text  \\\n",
       "0     FINAL REPORT EXAMINATION: CHEST (PA AND LAT) I...   \n",
       "1     FINAL REPORT INDICATION: History of left-sided...   \n",
       "2     FINAL REPORT EXAMINATION: Chest radiograph IND...   \n",
       "3     FINAL REPORT HISTORY: Chest pain. TECHNIQUE: U...   \n",
       "4     FINAL REPORT INDICATION: Pneumonia, cough, and...   \n",
       "...                                                 ...   \n",
       "2754  FINAL REPORT INDICATION: [REMOVED]M with cough...   \n",
       "2755  WET READ: [REMOVED] [REMOVED] [REMOVED] 4:26 P...   \n",
       "2756  WET READ: [REMOVED] [REMOVED] [REMOVED] 11:56 ...   \n",
       "2757  FINAL REPORT INDICATION: Cough and weakness. C...   \n",
       "2758  FINAL REPORT CHEST, TWO VIEWS, [REMOVED]. HIST...   \n",
       "\n",
       "                           examination  \\\n",
       "0                   chest (pa and lat)   \n",
       "1                                  NaN   \n",
       "2                     chest radiograph   \n",
       "3                                  NaN   \n",
       "4                                  NaN   \n",
       "...                                ...   \n",
       "2754                               NaN   \n",
       "2755  chest: frontal and lateral views   \n",
       "2756                 chest radiograph.   \n",
       "2757                               NaN   \n",
       "2758                               NaN   \n",
       "\n",
       "                                             indication  \\\n",
       "0                        history: [REMOVED]f with cough   \n",
       "1     history of left-sided weakness for 12 hours. p...   \n",
       "2     [REMOVED]m with cystic fibrosis and fever/coug...   \n",
       "3                                                   NaN   \n",
       "4            pneumonia, cough, and shortness of breath.   \n",
       "...                                                 ...   \n",
       "2754                   [REMOVED]m with cough // r/o pna   \n",
       "2755           history: [REMOVED]m with hypoxia // pna?   \n",
       "2756         [REMOVED]f with cough, fever, sob // ? pna   \n",
       "2757                                cough and weakness.   \n",
       "2758                                                NaN   \n",
       "\n",
       "                                              technique  \\\n",
       "0                                  chest pa and lateral   \n",
       "1              ap and lateral radiographs of the chest.   \n",
       "2                             frontal and lateral view.   \n",
       "3                         upright ap view of the chest.   \n",
       "4                                                   NaN   \n",
       "...                                                 ...   \n",
       "2754                 ap and lateral views of the chest.   \n",
       "2755                         chest: frontal and lateral   \n",
       "2756  single portable semi upright radiograph the ch...   \n",
       "2757                                                NaN   \n",
       "2758                                                NaN   \n",
       "\n",
       "                                             comparison  \\\n",
       "0                                             [REMOVED]   \n",
       "1                                                   NaN   \n",
       "2     comparison is made to multiple chest radiograp...   \n",
       "3                                            [REMOVED].   \n",
       "4     chest radiograph from [REMOVED] and chest ct f...   \n",
       "...                                                 ...   \n",
       "2754  [REMOVED]. [REMOVED] and ct torso from [REMOVED].   \n",
       "2755                                          [REMOVED]   \n",
       "2756                     chest ct: [REMOVED], [REMOVED]   \n",
       "2757  radiograph available from [REMOVED]. frontal a...   \n",
       "2758                                                NaN   \n",
       "\n",
       "                                               findings  \\\n",
       "0     cardiac silhouette size is normal. mediastinal...   \n",
       "1     mild cardiomegaly has been stable compared to ...   \n",
       "2     right chest wall port-a-cath ends at the cavoa...   \n",
       "3     low lung volumes limit assessment of the lung ...   \n",
       "4                                                   NaN   \n",
       "...                                                 ...   \n",
       "2754  vague opacity projecting over the right mid/lo...   \n",
       "2755  bilateral patchy pulmonary opacities appear sl...   \n",
       "2756  extensive bronchiectasis is again noted in the...   \n",
       "2757                                                NaN   \n",
       "2758  ap and lateral views of the chest are compared...   \n",
       "\n",
       "                                             impression  has_comparison  \\\n",
       "0     findings concerning for multifocal pneumonia. ...            True   \n",
       "1     interval increase in consolidation at the left...           False   \n",
       "2     chronic changes of cystic fibrosis as describe...            True   \n",
       "3     low lung volumes limit assessment of the lung ...            True   \n",
       "4     stable lingular and increased right middle lob...            True   \n",
       "...                                                 ...             ...   \n",
       "2754  vague right mid/lower opacity, nonspecific the...            True   \n",
       "2755  patchy bilateral mid to lower lung opacities a...            True   \n",
       "2756  extensive bilateral bronchiectasis, with super...            True   \n",
       "2757  1. increase in density of a right lower and mi...            True   \n",
       "2758  no definite acute cardiopulmonary process base...           False   \n",
       "\n",
       "      report_length                                      radgraph_text  \\\n",
       "0               645  cardiac silhouette size is normal. mediastinal...   \n",
       "1               806  mild cardiomegaly has been stable compared to ...   \n",
       "2              1136  right chest wall port-a-cath ends at the cavoa...   \n",
       "3               685  low lung volumes limit assessment of the lung ...   \n",
       "4               600                                                nan   \n",
       "...             ...                                                ...   \n",
       "2754            695  vague opacity projecting over the right mid/lo...   \n",
       "2755           1760  bilateral patchy pulmonary opacities appear sl...   \n",
       "2756           1100  extensive bronchiectasis is again noted in the...   \n",
       "2757            649                                                nan   \n",
       "2758            550  ap and lateral views of the chest are compared...   \n",
       "\n",
       "                                               extracts  \n",
       "0     {'0': {'text': 'cardiac silhouette size is nor...  \n",
       "1     {'0': {'text': 'mild cardiomegaly has been sta...  \n",
       "2     {'0': {'text': 'right chest wall port - a - ca...  \n",
       "3     {'0': {'text': 'low lung volumes limit assessm...  \n",
       "4     {'0': {'text': 'nan', 'entities': {}, 'data_so...  \n",
       "...                                                 ...  \n",
       "2754  {'0': {'text': 'vague opacity projecting over ...  \n",
       "2755  {'0': {'text': 'bilateral patchy pulmonary opa...  \n",
       "2756  {'0': {'text': 'extensive bronchiectasis is ag...  \n",
       "2757  {'0': {'text': 'nan', 'entities': {}, 'data_so...  \n",
       "2758  {'0': {'text': 'ap and lateral views of the ch...  \n",
       "\n",
       "[2759 rows x 14 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "radgraph_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Code "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERTopic Using RADGRAPH ENTITIES ONLY "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def extract_radgraph_entities(radgraph_dict):\n",
    "    entities = json.loads(radgraph_dict)\n",
    "    return [e[\"text\"] for e in entities[\"entities\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERTopic Using RADGRAPH ENTITIES AND RELATIONS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cardiac is an anatomy. silhouette modifies cardiac. size modifies cardiac. normal is located at cardiac. mediastinal is an anatomy. hilar is an anatomy. contours modifies hilar. unremarkable is located at hilar. pulmonary modifies vasculature. vasculature is an anatomy. normal is located at vasculature. ill - defined modifies opacities. parenchymal is an anatomy. opacities is located at lung. bilaterally modifies parenchymal. pronounced is an observation. both modifies lung. lung is an anatomy. bases modifies lung. multifocal modifies pneumonia. pneumonia is an observation. pleural is an anatomy. effusion is located at pleural. pneumothorax is an observation. acute modifies abnormalities. osseous is an anatomy. abnormalities is located at osseous. multifocal modifies pneumonia. pneumonia is an observation.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def process_radgraph_extracts(extracts_json):\n",
    "    \"\"\"\n",
    "    Converts RadGraph 'extracts' into structured clinical text for BERTopic.\n",
    "\n",
    "    Args:\n",
    "    - extracts_json (str or dict): RadGraph JSON stored in the 'extracts' column.\n",
    "\n",
    "    Returns:\n",
    "    - str: Reformatted text with preserved relations.\n",
    "    \"\"\"\n",
    "    if isinstance(extracts_json, str):\n",
    "        extracts_json = json.loads(extracts_json)  # Convert string to dict if needed\n",
    "\n",
    "    # Extract only the first key (assumed report ID or study ID)\n",
    "    first_key = list(extracts_json.keys())[0]\n",
    "    radgraph_data = extracts_json[first_key]\n",
    "\n",
    "    entities = radgraph_data.get(\"entities\", {})\n",
    "    sentences = []\n",
    "    \n",
    "    entity_map = {eid: entity[\"tokens\"] for eid, entity in entities.items()}  # ID → Text map\n",
    "\n",
    "    # Convert relations into readable text\n",
    "    for eid, entity in entities.items():\n",
    "        entity_text = entity[\"tokens\"]\n",
    "        entity_label = entity[\"label\"].split(\"::\")[0]  # Keep main category (Anatomy, Observation)\n",
    "        relations = entity.get(\"relations\", [])\n",
    "\n",
    "        # Base description of the entity\n",
    "        entity_sentence = f\"{entity_text} is an {entity_label.lower()}.\"\n",
    "        \n",
    "        # Add relational information\n",
    "        for rel in relations:\n",
    "            relation_type, target_eid = rel\n",
    "            target_text = entity_map.get(target_eid, \"\")\n",
    "            \n",
    "            if relation_type == \"modify\":\n",
    "                entity_sentence = f\"{entity_text} modifies {target_text}.\"\n",
    "            elif relation_type == \"located_at\":\n",
    "                entity_sentence = f\"{entity_text} is located at {target_text}.\"\n",
    "            elif relation_type == \"associated_with\":\n",
    "                entity_sentence = f\"{entity_text} is associated with {target_text}.\"\n",
    "        \n",
    "        sentences.append(entity_sentence)\n",
    "\n",
    "    return \" \".join(sentences)\n",
    "\n",
    "# Apply processing to the entire 'extracts' column\n",
    "# Apply to a sample (radgraph extract for the first study)\n",
    "sample_extract = process_radgraph_extracts(radgraph_tensor['extracts'][0])\n",
    "print(sample_extract)\n",
    "\n",
    "radgraph_tensor[\"processed_radgraph\"] = radgraph_tensor[\"extracts\"].apply(process_radgraph_extracts)\n",
    "radgraph_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "radgraph_tensor.to_csv('./processed_NER_extracts/processed_NER_extracts.csv')\n",
    "torch.save(radgraph_tensor, './processed_NER_extracts/processed_NER_extracts.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERTopic Radgraph - Document Representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/JanayeCheong/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import ipykernel\n",
    "ipykernel.__version__\n",
    "import scipy\n",
    "from scipy import stats\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# NLTK \n",
    "import re\n",
    "import nltk\n",
    "import umap.umap_ as UMAP\n",
    "from nltk import word_tokenize        \n",
    "nltk.download('wordnet')  \n",
    "from hdbscan import HDBSCAN\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from bertopic.representation import KeyBERTInspired\n",
    "from bertopic.vectorizers import ClassTfidfTransformer\n",
    "import pickle \n",
    "from bertopic.representation import MaximalMarginalRelevance\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import numpy \n",
    "\n",
    "# Path to the pre-trained model used for embeddings\n",
    "model_path = \"microsoft/BiomedVLP-CXR-BERT-specialized\"\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n",
    "embedding_model = AutoModel.from_pretrained(model_path, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "class NER_Extracts_Embedder:\n",
    "    def __init__(self, pretrained_model_name, pooling_strategy='cls'):\n",
    "        \"\"\"\n",
    "        Initialize the RadiologyReportEmbedder with a specified pooling strategy.\n",
    "\n",
    "        Parameters:\n",
    "            pretrained_model_name: Name of the pretrained model to load\n",
    "            pooling_strategy: Pooling strategy ('mean' or 'cls')\n",
    "        \"\"\"\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name, trust_remote_code=True)\n",
    "        self.model = AutoModel.from_pretrained(pretrained_model_name, trust_remote_code=True)\n",
    "        self.model.eval()  # Set to evaluation mode\n",
    "        self.pooling_strategy = pooling_strategy.lower()  # Ensure case-insensitivity\n",
    "        \n",
    "        if self.pooling_strategy not in ['mean', 'cls']:\n",
    "            raise ValueError(\"Invalid pooling strategy! Use 'mean' or 'cls'.\")\n",
    "\n",
    "    def create_embeddings(self, texts):\n",
    "        \"\"\"\n",
    "        Create embeddings for a list of radiology report texts.\n",
    "\n",
    "        Parameters:\n",
    "            texts: List of report texts to embed\n",
    "\n",
    "        Returns:\n",
    "            Normalized embeddings as a numpy array\n",
    "        \"\"\"\n",
    "        embeddings = []\n",
    "        batch_size = 32\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for i in range(0, len(texts), batch_size):\n",
    "                batch_texts = texts[i:i + batch_size]\n",
    "                \n",
    "                inputs = self.tokenizer(\n",
    "                    batch_texts,\n",
    "                    padding=True,\n",
    "                    truncation=True,\n",
    "                    max_length=512,  # Adjust max length if needed\n",
    "                    return_tensors=\"pt\"\n",
    "                )\n",
    "                \n",
    "                outputs = self.model(**inputs)\n",
    "                \n",
    "                # Apply the selected pooling strategy\n",
    "                if self.pooling_strategy == 'cls':\n",
    "                    # Use [CLS] token embedding\n",
    "                    batch_embeddings = outputs.last_hidden_state[:, 0, :]\n",
    "                else:  # Mean pooling\n",
    "                    attention_mask = inputs['attention_mask']\n",
    "                    batch_embeddings = self._mean_pooling(outputs.last_hidden_state, attention_mask)\n",
    "                \n",
    "                embeddings.append(batch_embeddings.numpy())\n",
    "        \n",
    "        embeddings = np.vstack(embeddings)\n",
    "        embeddings = normalize(embeddings)\n",
    "        \n",
    "        # Save the model for the specific pooling strategy\n",
    "        model_save_path = f'../../models/CXR_BERT_{self.pooling_strategy}_model'\n",
    "        self.model.save_pretrained(model_save_path)\n",
    "        print(f\"Model saved at: {model_save_path}\")\n",
    "        \n",
    "        return embeddings\n",
    "\n",
    "    def _mean_pooling(self, token_embeddings, attention_mask):\n",
    "        \"\"\"\n",
    "        Perform mean pooling on token embeddings using the attention mask.\n",
    "        \"\"\"\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pneumonia_reports(reports_df, pretrained_model_name, pooling_strategy='mean'):\n",
    "    \"\"\"\n",
    "    Process pneumonia reports and create embeddings with the specified pooling strategy.\n",
    "\n",
    "    Parameters:\n",
    "        reports_df: DataFrame containing the radiology reports\n",
    "        pretrained_model_name: Name of the pretrained model to use\n",
    "        pooling_strategy: Pooling strategy ('mean' or 'cls')\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with embeddings added\n",
    "    \"\"\"\n",
    "    # Initialize the embedder\n",
    "    embedder = RadiologyReportEmbedder(pretrained_model_name, pooling_strategy=pooling_strategy)\n",
    "    \n",
    "    # Combine relevant sections for embedding\n",
    "    reports_df['embedding_text'] = reports_df.apply(\n",
    "        lambda x: f\"Findings: {x['findings']} Impression: {x['impression']}\", \n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # Create and add embeddings\n",
    "    embeddings = embedder.create_embeddings(reports_df['embedding_text'].tolist())\n",
    "    torch.save(embeddings, f'radiology_embeddings_{pooling_strategy}.pt')\n",
    "    print(f\"Embeddings saved to: radiology_embeddings_{pooling_strategy}.pt\")\n",
    "    reports_df['embedding'] = embeddings.tolist()\n",
    "    \n",
    "    return reports_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reports_df = pd.read_csv('structured_reports.csv')\n",
    "embedded_reports_df = process_pneumonia_reports(reports_df, pretrained_model_name='microsoft/BiomedVLP-CXR-BERT-specialized')\n",
    "embedded_reports_df.to_csv('embedded_reports_cls.csv')\n",
    "embeddings = embedded_reports_df['embedding'].tolist()\n",
    "torch.save(embeddings, 'radiology_embeddings_cls.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from bertopic import BERTopic\n",
    "import umap\n",
    "import hdbscan\n",
    "\n",
    "class ClinicalOutcomePredictor:\n",
    "    def __init__(self):\n",
    "        self.outcomes = ['icu_stay', 'ventilator', 'expired', 'sepsis', 'severe']\n",
    "        self.models = {outcome: {} for outcome in self.outcomes}\n",
    "        \n",
    "    def process_radgraph_to_structured(self, radgraph_extracts):\n",
    "        \"\"\"Convert RadGraph extracts to structured format\"\"\"\n",
    "        structured_texts = []\n",
    "        for extract in radgraph_extracts:\n",
    "            # Convert relationships to structured sentences\n",
    "            structured = []\n",
    "            entities = {}\n",
    "            relations = []\n",
    "            \n",
    "            # Parse each statement\n",
    "            for statement in extract.split('. '):\n",
    "                if 'is an' in statement:\n",
    "                    entity, type_ = statement.split(' is an ')\n",
    "                    entities[entity] = type_\n",
    "                elif 'modifies' in statement:\n",
    "                    modifier, target = statement.split(' modifies ')\n",
    "                    relations.append(f\"{modifier}_modifies_{target}\")\n",
    "                elif 'located at' in statement:\n",
    "                    finding, location = statement.split(' is located at ')\n",
    "                    relations.append(f\"{finding}_at_{location}\")\n",
    "                elif 'associated with' in statement:\n",
    "                    source, target = statement.split(' is associated with ')\n",
    "                    relations.append(f\"{source}_associates_{target}\")\n",
    "            \n",
    "            # Create structured representation\n",
    "            structured_text = \" \".join([\n",
    "                f\"{entity}_{type_}\" for entity, type_ in entities.items()\n",
    "            ] + relations)\n",
    "            \n",
    "            structured_texts.append(structured_text)\n",
    "            \n",
    "        return structured_texts\n",
    "\n",
    "    def create_bertopic_model(self, texts, n_topics=50):\n",
    "        \"\"\"Create and train BERTopic model\"\"\"\n",
    "        # Initialize BERTopic with custom parameters\n",
    "        topic_model = BERTopic(\n",
    "            n_topics=n_topics,\n",
    "            min_topic_size=5,\n",
    "            umap_model=umap.UMAP(\n",
    "                n_neighbors=15,\n",
    "                n_components=5,\n",
    "                min_dist=0.0,\n",
    "                metric='cosine'\n",
    "            ),\n",
    "            hdbscan_model=hdbscan.HDBSCAN(\n",
    "                min_cluster_size=5,\n",
    "                metric='euclidean',\n",
    "                cluster_selection_method='eom'\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Fit the model and transform documents\n",
    "        topics, probs = topic_model.fit_transform(texts)\n",
    "        return topic_model, probs\n",
    "\n",
    "    def train_outcome_models(self, \n",
    "                           raw_reports,\n",
    "                           radgraph_extracts,\n",
    "                           outcome_labels,\n",
    "                           embedder=\"microsoft/BiomedVLP-CXR-BERT-general\"):\n",
    "        \"\"\"\n",
    "        Train models using different text representations\n",
    "        \"\"\"\n",
    "        # 1. Process raw embeddings\n",
    "        tokenizer = AutoTokenizer.from_pretrained(embedder)\n",
    "        model = AutoModel.from_pretrained(embedder)\n",
    "        \n",
    "        raw_embeddings = []\n",
    "        for report in raw_reports:\n",
    "            inputs = tokenizer(report, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "            with torch.no_grad():\n",
    "                outputs = model(**inputs)\n",
    "            # Use [CLS] token embedding\n",
    "            raw_embeddings.append(outputs.last_hidden_state[:, 0, :].numpy())\n",
    "        raw_embeddings = np.vstack(raw_embeddings)\n",
    "        \n",
    "        # 2. Process structured RadGraph texts\n",
    "        structured_texts = self.process_radgraph_to_structured(radgraph_extracts)\n",
    "        structured_embeddings = []\n",
    "        for text in structured_texts:\n",
    "            inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "            with torch.no_grad():\n",
    "                outputs = model(**inputs)\n",
    "            structured_embeddings.append(outputs.last_hidden_state[:, 0, :].numpy())\n",
    "        structured_embeddings = np.vstack(structured_embeddings)\n",
    "        \n",
    "        # 3. Create BERTopic representations\n",
    "        topic_model, topic_probs = self.create_bertopic_model(structured_texts)\n",
    "        \n",
    "        # Train models for each outcome\n",
    "        results = {}\n",
    "        for outcome in self.outcomes:\n",
    "            outcome_labels = outcome_labels[outcome]\n",
    "            \n",
    "            # Train models using different representations\n",
    "            representations = {\n",
    "                'raw_embeddings': raw_embeddings,\n",
    "                'structured_embeddings': structured_embeddings,\n",
    "                'topic_probs': topic_probs\n",
    "            }\n",
    "            \n",
    "            outcome_results = {}\n",
    "            for rep_name, features in representations.items():\n",
    "                # Split data\n",
    "                X_train, X_test, y_train, y_test = train_test_split(\n",
    "                    features, outcome_labels, test_size=0.2, random_state=42\n",
    "                )\n",
    "                \n",
    "                # Train model\n",
    "                model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "                model.fit(X_train, y_train)\n",
    "                \n",
    "                # Evaluate\n",
    "                y_pred = model.predict(X_test)\n",
    "                y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "                \n",
    "                metrics = {\n",
    "                    'classification_report': classification_report(y_test, y_pred),\n",
    "                    'roc_auc': roc_auc_score(y_test, y_pred_proba)\n",
    "                }\n",
    "                \n",
    "                # Store model and results\n",
    "                self.models[outcome][rep_name] = model\n",
    "                outcome_results[rep_name] = metrics\n",
    "            \n",
    "            results[outcome] = outcome_results\n",
    "        \n",
    "        return results, topic_model\n",
    "\n",
    "    def analyze_feature_importance(self, outcome, representation):\n",
    "        \"\"\"Analyze which features are most important for prediction\"\"\"\n",
    "        model = self.models[outcome][representation]\n",
    "        \n",
    "        if representation == 'topic_probs':\n",
    "            # Get topic interpretations\n",
    "            important_topics = pd.DataFrame({\n",
    "                'topic_id': range(len(model.feature_importances_)),\n",
    "                'importance': model.feature_importances_\n",
    "            }).sort_values('importance', ascending=False)\n",
    "            \n",
    "            return important_topics\n",
    "        else:\n",
    "            # For embeddings, we can only show importance scores\n",
    "            feature_importance = pd.DataFrame({\n",
    "                'feature_id': range(len(model.feature_importances_)),\n",
    "                'importance': model.feature_importances_\n",
    "            }).sort_values('importance', ascending=False)\n",
    "            \n",
    "            return feature_importance\n",
    "\n",
    "    def predict_outcomes(self, new_reports, new_radgraph_extracts):\n",
    "        \"\"\"Predict outcomes for new reports using all models\"\"\"\n",
    "        # Process new reports similar to training\n",
    "        # Return predictions from each model\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
