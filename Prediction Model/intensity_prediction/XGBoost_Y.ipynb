{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model the Severity of the Pneumonia Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded HDBSCAN probabilities!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Load the BERTopic HDBSCAN probabilities with weights_only=False\n",
    "doc_topic_probabilities = torch.load('../../models/BERTopic_All_Pneumonia_Type/representations/specter_representation_keybert_mmr/specter_probabilities_keybert_mmr.pt',\n",
    "                                     weights_only=False)\n",
    "\n",
    "print(\"Successfully loaded HDBSCAN probabilities!\")\n",
    "doc_topic_probabilities.shape\n",
    "\n",
    "pneumonia_type_df=pd.read_csv('../../NLP_processing/NER_embeddings/pneumonia_type/radgraph_with_embeddings.csv')\n",
    "\n",
    "\n",
    "# Remove NaN or empty radgraph_text entries\n",
    "pneumonia_type_df = pneumonia_type_df[pneumonia_type_df['radgraph_text'].notna()]\n",
    "pneumonia_type_df = pneumonia_type_df[pneumonia_type_df['radgraph_text'].str.strip() != '']\n",
    "\n",
    "# Extract clean docs and embeddings\n",
    "docs = pneumonia_type_df['radgraph_text'].astype(str).tolist()\n",
    "embeddings = np.vstack(pneumonia_type_df['embedding'].values)\n",
    "\n",
    "# Ensure shape consistency\n",
    "assert len(docs) == embeddings.shape[0], \"Mismatch between docs and embeddings!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved BERTopic probabilities with study IDs to 'bertopic_study_probabilities.csv'\n"
     ]
    }
   ],
   "source": [
    "# Convert probabilities to a DataFrame\n",
    "\n",
    "# Ensure 'study_id' exists and extract it\n",
    "study_ids = pneumonia_type_df[\"study_id\"].tolist()\n",
    "\n",
    "\n",
    "topic_prob_df = pd.DataFrame(doc_topic_probabilities, columns=[f\"Topic_{i}\" for i in range(doc_topic_probabilities.shape[1])])\n",
    "\n",
    "# Add study_id to align with original data\n",
    "topic_prob_df[\"study_id\"] = study_ids\n",
    "\n",
    "# Save this as a CSV for verification\n",
    "topic_prob_df.to_csv(\"bertopic_study_probabilities.csv\", index=False)\n",
    "print(\"âœ… Saved BERTopic probabilities with study IDs to 'bertopic_study_probabilities.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset shape: (1876, 45)\n",
      "Test dataset shape: (462, 45)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_cohort = pd.read_csv('cohort_train.csv')\n",
    "train_ids = train_cohort['study_id'].to_list()\n",
    "\n",
    "test_cohort = pd.read_csv('cohort_test.csv')\n",
    "test_ids = test_cohort['study_id'].to_list()\n",
    "\n",
    "# Merge with training cohort\n",
    "train_df = train_cohort.merge(topic_prob_df, on=\"study_id\", how=\"inner\")\n",
    "\n",
    "# Merge with testing cohort\n",
    "test_df = test_cohort.merge(topic_prob_df, on=\"study_id\", how=\"inner\")\n",
    "\n",
    "# Save the final datasets\n",
    "train_df.to_csv(\"train_bertopic_probabilities.csv\", index=False)\n",
    "test_df.to_csv(\"test_bertopic_probabilities.csv\", index=False)\n",
    "\n",
    "# Print shapes to verify\n",
    "print(f\"Train dataset shape: {train_df.shape}\")\n",
    "print(f\"Test dataset shape: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BERTopic probability embeddings for the training and test sets\n",
    "train_embeddings_df = pd.read_csv(\"train_bertopic_probabilities.csv\")\n",
    "test_embeddings_df = pd.read_csv(\"test_bertopic_probabilities.csv\")\n",
    "\n",
    "# Ensure 'study_id' column exists in embeddings\n",
    "if 'study_id' not in train_embeddings_df.columns or 'study_id' not in test_embeddings_df.columns:\n",
    "    raise ValueError(\"Error: 'study_id' column is missing in embeddings CSV files.\")\n",
    "\n",
    "# Merge the BERTopic embeddings with the train/test cohort metadata\n",
    "train_cohort = train_cohort.merge(train_embeddings_df, on=\"study_id\", how=\"inner\")\n",
    "test_cohort = test_cohort.merge(test_embeddings_df, on=\"study_id\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (1876, 34), Labels: (2207,)\n",
      "Test shape: (462, 34), Labels: (552,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the cohort files\n",
    "train_cohort = pd.read_csv(\"cohort_train.csv\")\n",
    "test_cohort = pd.read_csv(\"cohort_test.csv\")\n",
    "\n",
    "# Load the BERTopic probabilities DataFrame\n",
    "embeddings_df = pd.read_csv(\"bertopic_study_probabilities.csv\")  # Replace with actual path\n",
    "\n",
    "# Extract only `study_id` and topic columns (Topic_0, Topic_1, ..., Topic_33)\n",
    "topic_columns = [col for col in embeddings_df.columns if col.startswith(\"Topic_\")]\n",
    "study_topic_df = embeddings_df[[\"study_id\"] + topic_columns]\n",
    "\n",
    "# Filter training and testing sets based on `study_id`\n",
    "train_df = study_topic_df[study_topic_df[\"study_id\"].isin(train_cohort[\"study_id\"])]\n",
    "test_df = study_topic_df[study_topic_df[\"study_id\"].isin(test_cohort[\"study_id\"])]\n",
    "\n",
    "# Convert topic probabilities to NumPy arrays\n",
    "X_train = train_df[topic_columns].to_numpy()\n",
    "X_test = test_df[topic_columns].to_numpy()\n",
    "\n",
    "# Labels for training/testing (assuming `Y` is the label column in the cohort files)\n",
    "y_train = train_cohort[\"Y\"].values\n",
    "y_test = test_cohort[\"Y\"].values\n",
    "\n",
    "# Print shapes to verify\n",
    "print(f\"Train shape: {X_train.shape}, Labels: {y_train.shape}\")\n",
    "print(f\"Test shape: {X_test.shape}, Labels: {y_test.shape}\")\n",
    "\n",
    "# Save filtered train & test data\n",
    "train_df.to_csv(\"train_embeddings.csv\", index=False)\n",
    "test_df.to_csv(\"test_embeddings.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Train dataset shape: (1876, 45)\n",
      "âœ… Test dataset shape: (462, 45)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load Train & Test Cohorts\n",
    "train_cohort = pd.read_csv(\"cohort_train.csv\")\n",
    "test_cohort = pd.read_csv(\"cohort_test.csv\")\n",
    "\n",
    "# Load BERTopic Probabilities (Make sure this file contains study_id + topic columns)\n",
    "topic_prob_df = pd.read_csv(\"bertopic_study_probabilities.csv\")  \n",
    "\n",
    "# Merge with Training Cohort\n",
    "train_df = train_cohort.merge(topic_prob_df, on=\"study_id\", how=\"inner\")\n",
    "\n",
    "# Merge with Testing Cohort\n",
    "test_df = test_cohort.merge(topic_prob_df, on=\"study_id\", how=\"inner\")\n",
    "\n",
    "# Save the final datasets\n",
    "train_df.to_csv(\"train_bertopic_probabilities.csv\", index=False)\n",
    "test_df.to_csv(\"test_bertopic_probabilities.csv\", index=False)\n",
    "\n",
    "# Print shapes to verify\n",
    "print(f\"âœ… Train dataset shape: {train_df.shape}\")\n",
    "print(f\"âœ… Test dataset shape: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Model Performance Metrics:\n",
      "âœ… Accuracy: 0.7857\n",
      "âœ… AUC-ROC: 0.6020\n",
      "âœ… F1 Score: 0.1391\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score\n",
    "\n",
    "# Load Processed Train & Test Data\n",
    "train_df = pd.read_csv(\"train_bertopic_probabilities.csv\")\n",
    "test_df = pd.read_csv(\"test_bertopic_probabilities.csv\")\n",
    "\n",
    "# Identify Topic Columns (Automatically detect Topic_* columns)\n",
    "topic_columns = [col for col in train_df.columns if col.startswith(\"Topic_\")]\n",
    "\n",
    "# Extract Features (Topic Probabilities) and Labels (Y)\n",
    "X_train = train_df[topic_columns].to_numpy()\n",
    "X_test = test_df[topic_columns].to_numpy()\n",
    "y_train = train_df[\"Y\"].values  # Labels\n",
    "y_test = test_df[\"Y\"].values  # Labels\n",
    "\n",
    "# Train XGBoost Model\n",
    "model = xgb.XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Compute Metrics\n",
    "metrics = {\n",
    "    \"accuracy\": accuracy_score(y_test, y_pred),\n",
    "    \"auc\": roc_auc_score(y_test, y_pred_proba),\n",
    "    \"f1\": f1_score(y_test, y_pred)\n",
    "}\n",
    "\n",
    "# Print Performance Metrics\n",
    "print(\"\\nðŸ“Š Model Performance Metrics:\")\n",
    "print(f\"âœ… Accuracy: {metrics['accuracy']:.4f}\")\n",
    "print(f\"âœ… AUC-ROC: {metrics['auc']:.4f}\")\n",
    "print(f\"âœ… F1 Score: {metrics['f1']:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
