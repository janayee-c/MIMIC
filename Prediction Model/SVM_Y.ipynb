{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test embeddings shape: (2207, 14)\n",
      "Test embeddings shape: (552, 14)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_cohort = pd.read_csv('cohort_train.csv')\n",
    "train_ids = train_cohort['study_id'].to_list()\n",
    "\n",
    "test_cohort = pd.read_csv('cohort_test.csv')\n",
    "test_ids = test_cohort['study_id'].to_list()\n",
    "\n",
    "# Load embeddings\n",
    "embeddings_df = pd.read_csv('../NLP_processing/embeddings/intense_pneumonia_embeddings/embedded_reports_mean.csv')  \n",
    "\n",
    "embeddings_train = embeddings_df[embeddings_df['study_id'].isin(train_ids)]\n",
    "embeddings_test= embeddings_df[embeddings_df['study_id'].isin(test_ids)]\n",
    "\n",
    "print(f\"Test embeddings shape: {embeddings_train .shape}\")\n",
    "print(f\"Test embeddings shape: {embeddings_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training embeddings shape: (2207, 2)\n",
      "Test embeddings shape: (552, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gd/p6nf_1w11938t89t0bj2r9lc0000gn/T/ipykernel_21692/3944836315.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  embedded_reports_tensor = torch.load('../NLP_processing/embeddings/intense_pneumonia_embeddings/attention_results_embedded_reports.pt')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# Load the embedded reports tensor\n",
    "embedded_reports_tensor = torch.load('../NLP_processing/embeddings/intense_pneumonia_embeddings/attention_results_embedded_reports.pt')\n",
    "\n",
    "# Extract the relevant data from the tensor\n",
    "embeddings = embedded_reports_tensor['embeddings']\n",
    "study_ids = embedded_reports_tensor['study_ids']\n",
    "\n",
    "# Create a DataFrame to associate embeddings with study IDs\n",
    "embeddings_df = pd.DataFrame({\n",
    "    'study_id': study_ids,\n",
    "    'embedding': list(embeddings)  # Convert array rows to list for pandas compatibility\n",
    "})\n",
    "\n",
    "# Load training and testing cohort study IDs\n",
    "train_cohort = pd.read_csv('cohort_train.csv')\n",
    "train_ids = train_cohort['study_id'].to_list()\n",
    "\n",
    "test_cohort = pd.read_csv('cohort_test.csv')\n",
    "test_ids = test_cohort['study_id'].to_list()\n",
    "\n",
    "# Filter embeddings for training and testing cohorts\n",
    "embeddings_train = embeddings_df[embeddings_df['study_id'].isin(train_ids)]\n",
    "embeddings_test = embeddings_df[embeddings_df['study_id'].isin(test_ids)]\n",
    "\n",
    "print(f\"Training embeddings shape: {embeddings_train.shape}\")\n",
    "print(f\"Test embeddings shape: {embeddings_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score, roc_auc_score, f1_score, \n",
    "    recall_score, precision_score, confusion_matrix,\n",
    "    classification_report\n",
    ")\n",
    "import numpy as np\n",
    "\n",
    "class SVMRadiologyClassifier:\n",
    "    def __init__(self, train_df, test_df, embeddings_train, embeddings_test):\n",
    "        \"\"\"\n",
    "        Initialize the SVM classifier with separate training and test datasets.\n",
    "        \n",
    "        Parameters:\n",
    "            train_df: DataFrame containing the training cohort reports and metadata\n",
    "            test_df: DataFrame containing the test cohort reports and metadata\n",
    "            embeddings_train: Pre-computed embeddings for training cohort\n",
    "            embeddings_test: Pre-computed embeddings for test cohort\n",
    "        \"\"\"\n",
    "        self.train_df = train_df\n",
    "        self.test_df = test_df\n",
    "        \n",
    "        # Convert string embeddings to numpy arrays if needed\n",
    "        self.embeddings_train = np.array([\n",
    "            np.array(ast.literal_eval(emb)) if isinstance(emb, str) else emb \n",
    "            for emb in embeddings_train['embedding']\n",
    "        ])\n",
    "        self.embeddings_test = np.array([\n",
    "            np.array(ast.literal_eval(emb)) if isinstance(emb, str) else emb \n",
    "            for emb in embeddings_test['embedding']\n",
    "        ])\n",
    "        \n",
    "        self.model = None\n",
    "        self.scaler = StandardScaler()\n",
    "        self.misclassified_cases = None\n",
    "        \n",
    "    def prepare_data(self):\n",
    "        \"\"\"\n",
    "        Prepare and scale the data from the separate train and test cohorts.\n",
    "        \"\"\"\n",
    "        # Get labels\n",
    "        y_train = self.train_df['Y'].values\n",
    "        y_test = self.test_df['Y'].values\n",
    "        \n",
    "        # Scale the embeddings\n",
    "        X_train = self.scaler.fit_transform(self.embeddings_train)\n",
    "        X_test = self.scaler.transform(self.embeddings_test)\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test\n",
    "    \n",
    "    \n",
    "    def train_and_evaluate(self, kernel='rbf', C=2.0, probability=True): # made C slightly higher for tighter margin \n",
    "        \"\"\"\n",
    "        Train the SVM model and evaluate its performance on the test set.\n",
    "        Handles different sizes between training and test sets.\n",
    "        \"\"\"\n",
    "        X_train, X_test, y_train, y_test = self.prepare_data()\n",
    "        \n",
    "\n",
    "        self.model = SVC(\n",
    "            kernel=kernel,\n",
    "            C=C,\n",
    "            probability=probability,\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "        self.model.fit(X_train, y_train)\n",
    "    \n",
    "        y_pred = self.model.predict(X_test)\n",
    "        y_pred_proba = self.model.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "\n",
    "        if len(y_test) != len(y_pred):\n",
    "            print(f\"Note: Train set has {len(y_train)} samples, Test set has {len(y_test)} samples\")\n",
    "            y_pred = y_pred[:len(y_test)]\n",
    "            y_pred_proba = y_pred_proba[:len(y_test)]\n",
    "        \n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        \n",
    "        metrics = {\n",
    "            'accuracy': accuracy_score(y_test, y_pred),\n",
    "            'auc': roc_auc_score(y_test, y_pred_proba),\n",
    "            'f1': f1_score(y_test, y_pred),\n",
    "            'sensitivity': tp / (tp + fn),  # True Positive Rate / Recall\n",
    "            'specificity': tn / (tn + fp)   # True Negative Rate\n",
    "        }\n",
    "        \n",
    "        # Examine misclassified\n",
    "        misclassified_mask = y_test != y_pred\n",
    "        self.misclassified_cases = self.test_df[misclassified_mask].copy()\n",
    "        self.misclassified_cases['predicted_label'] = y_pred[misclassified_mask]\n",
    "        self.misclassified_cases['true_label'] = y_test[misclassified_mask]\n",
    "        self.misclassified_cases['prediction_probability'] = y_pred_proba[misclassified_mask]\n",
    "    \n",
    "        return metrics\n",
    "\n",
    "    \n",
    "    def analyze_misclassified_cases(self):\n",
    "        \"\"\"\n",
    "        Analyze cases where the model made mistakes.\n",
    "        \"\"\"\n",
    "        if self.misclassified_cases is None:\n",
    "            print(\"Please run train_and_evaluate first.\")\n",
    "            return\n",
    "        \n",
    "        print(\"\\nAnalysis of Misclassified Cases:\")\n",
    "        print(f\"Total misclassified cases: {len(self.misclassified_cases)}\")\n",
    "        \n",
    "        # Analyze false positives and negatives\n",
    "        false_positives = self.misclassified_cases[\n",
    "            (self.misclassified_cases['predicted_label'] == 1) & \n",
    "            (self.misclassified_cases['true_label'] == 0)\n",
    "        ]\n",
    "        \n",
    "        false_negatives = self.misclassified_cases[\n",
    "            (self.misclassified_cases['predicted_label'] == 0) & \n",
    "            (self.misclassified_cases['true_label'] == 1)\n",
    "        ]\n",
    "        \n",
    "        print(f\"\\nFalse Positives: {len(false_positives)} cases\")\n",
    "        print(f\"False Negatives: {len(false_negatives)} cases\")\n",
    "        \n",
    "        # Display example cases\n",
    "        def display_cases(cases, case_type, n=5):\n",
    "            print(f\"\\nExample {case_type} (showing {min(n, len(cases))} cases):\")\n",
    "            for _, case in cases.head(n).iterrows():\n",
    "                print(f\"\\nStudy ID: {case['study_id']}\")\n",
    "                print(f\"Confidence: {case['prediction_probability']:.3f}\")\n",
    "                print(\"-\" * 80)\n",
    "        \n",
    "        display_cases(false_positives, \"False Positives\")\n",
    "        display_cases(false_negatives, \"False Negatives\")\n",
    "        \n",
    "        return false_positives, false_negatives\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to run the SVM classification pipeline.\n",
    "    \"\"\"\n",
    "    # Run Classifier\n",
    "    classifier = SVMRadiologyClassifier(\n",
    "        train_cohort, \n",
    "        test_cohort, \n",
    "        embeddings_train, \n",
    "        embeddings_test\n",
    "    )\n",
    "    \n",
    "    # Train and evaluate with different kernel options\n",
    "    kernels = ['rbf', 'linear']\n",
    "    best_metrics = None\n",
    "    best_kernel = None\n",
    "    \n",
    "    for kernel in kernels:\n",
    "        print(f\"\\nTraining with {kernel} kernel:\")\n",
    "        metrics = classifier.train_and_evaluate(kernel=kernel)\n",
    "        \n",
    "        print(\"\\nModel Performance Metrics:\")\n",
    "        print(f\"Accuracy: {metrics['accuracy']:.4f}\")\n",
    "        print(f\"AUC-ROC: {metrics['auc']:.4f}\")\n",
    "        print(f\"F1 Score: {metrics['f1']:.4f}\")\n",
    "        print(f\"Sensitivity: {metrics['sensitivity']:.4f}\")\n",
    "        \n",
    "        if best_metrics is None or metrics['auc'] > best_metrics['auc']:\n",
    "            best_metrics = metrics\n",
    "            best_kernel = kernel\n",
    "    \n",
    "    print(f\"\\nBest performing kernel: {best_kernel}\")\n",
    "    \n",
    "    false_positives, false_negatives = classifier.analyze_misclassified_cases()\n",
    "    return classifier, best_metrics, (false_positives, false_negatives)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with rbf kernel:\n",
      "\n",
      "Model Performance Metrics:\n",
      "Accuracy: 0.7482\n",
      "AUC-ROC: 0.5379\n",
      "F1 Score: 0.0142\n",
      "Sensitivity: 0.0071\n",
      "\n",
      "Training with linear kernel:\n",
      "\n",
      "Model Performance Metrics:\n",
      "Accuracy: 0.5942\n",
      "AUC-ROC: 0.4358\n",
      "F1 Score: 0.1825\n",
      "Sensitivity: 0.1786\n",
      "\n",
      "Best performing kernel: rbf\n",
      "\n",
      "Analysis of Misclassified Cases:\n",
      "Total misclassified cases: 224\n",
      "\n",
      "False Positives: 109 cases\n",
      "False Negatives: 115 cases\n",
      "\n",
      "Example False Positives (showing 5 cases):\n",
      "\n",
      "Study ID: 57219438\n",
      "Confidence: 0.237\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Study ID: 54264165\n",
      "Confidence: 0.239\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Study ID: 57321775\n",
      "Confidence: 0.237\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Study ID: 52128893\n",
      "Confidence: 0.242\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Study ID: 57298755\n",
      "Confidence: 0.238\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Example False Negatives (showing 5 cases):\n",
      "\n",
      "Study ID: 56822947\n",
      "Confidence: 0.236\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Study ID: 54589936\n",
      "Confidence: 0.230\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Study ID: 55976769\n",
      "Confidence: 0.234\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Study ID: 50078440\n",
      "Confidence: 0.236\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Study ID: 58054804\n",
      "Confidence: 0.228\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# loading XGBOOST Prediction Learning Data \n",
    "classifier, metrics, error_analysis = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import re\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.preprocessing import normalize, StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, confusion_matrix\n",
    "from bertopic import BERTopic\n",
    "from bertopic.vectorizers import ClassTfidfTransformer\n",
    "from bertopic.representation import MaximalMarginalRelevance, KeyBERTInspired\n",
    "from hdbscan import HDBSCAN\n",
    "from umap import UMAP\n",
    "\n",
    "class IntegratedRadiologyClassifier:\n",
    "    def __init__(self, pretrained_model_name, save_path='../../models/'):\n",
    "        \"\"\"\n",
    "        Initialize the integrated classifier with custom embedding model and BERTopic.\n",
    "        \"\"\"\n",
    "        self.save_path = Path(save_path)\n",
    "        self.embedder = RadiologyReportEmbedder(pretrained_model_name)\n",
    "        self.scaler = StandardScaler()\n",
    "        self.setup_bertopic()\n",
    "        self.svm = None\n",
    "        self.misclassified_cases = None\n",
    "        \n",
    "    def setup_bertopic(self):\n",
    "        \"\"\"\n",
    "        Initialize BERTopic with custom configuration.\n",
    "        \"\"\"\n",
    "        # UMAP configuration\n",
    "        self.umap_model = UMAP(\n",
    "            n_neighbors=30,\n",
    "            n_components=5,\n",
    "            min_dist=0.0,\n",
    "            metric='cosine'\n",
    "        )\n",
    "        \n",
    "        # HDBSCAN configuration\n",
    "        self.hdbscan_model = HDBSCAN(\n",
    "            min_samples=20,\n",
    "            gen_min_span_tree=True,\n",
    "            prediction_data=True,\n",
    "            min_cluster_size=20,\n",
    "            metric='euclidean',\n",
    "            cluster_selection_method='leaf'\n",
    "        )\n",
    "        \n",
    "        # Vectorizer configuration\n",
    "        self.vectorizer_model = CountVectorizer(\n",
    "            strip_accents='unicode',\n",
    "            stop_words='english',\n",
    "            ngram_range=(1, 3),\n",
    "            max_df=0.5\n",
    "        )\n",
    "        \n",
    "        # CTF-IDF configuration\n",
    "        self.ctfidf_model = ClassTfidfTransformer(\n",
    "            bm25_weighting=False,\n",
    "            reduce_frequent_words=True\n",
    "        )\n",
    "        \n",
    "        # Representation model configuration\n",
    "        self.representation_model = [\n",
    "            KeyBERTInspired(top_n_words=30, random_state=42),\n",
    "            MaximalMarginalRelevance(diversity=0.8)\n",
    "        ]\n",
    "        \n",
    "        # Initialize BERTopic\n",
    "        self.topic_model = BERTopic(\n",
    "            umap_model=self.umap_model,\n",
    "            hdbscan_model=self.hdbscan_model,\n",
    "            ctfidf_model=self.ctfidf_model,\n",
    "            vectorizer_model=self.vectorizer_model,\n",
    "            representation_model=self.representation_model,\n",
    "            top_n_words=30,\n",
    "            calculate_probabilities=True\n",
    "        )\n",
    "    \n",
    "    def process_and_embed_reports(self, reports_df):\n",
    "        \"\"\"\n",
    "        Process reports and create embeddings.\n",
    "        \"\"\"\n",
    "        # Combine relevant sections\n",
    "        reports_df['combined_text'] = reports_df.apply(\n",
    "            lambda x: f\"Findings: {x['findings']} Impression: {x['impression']}\", \n",
    "            axis=1\n",
    "        )\n",
    "        \n",
    "        # Create embeddings\n",
    "        embeddings = self.embedder.create_embeddings(reports_df['combined_text'].tolist())\n",
    "        return embeddings\n",
    "    \n",
    "    def fit_transform_topics(self, reports_df, embeddings):\n",
    "        \"\"\"\n",
    "        Fit BERTopic model and transform documents to topic space.\n",
    "        \"\"\"\n",
    "        docs = reports_df['combined_text'].tolist()\n",
    "        topics, probabilities = self.topic_model.fit_transform(\n",
    "            docs, \n",
    "            embeddings=embeddings\n",
    "        )\n",
    "        return topics, probabilities\n",
    "    \n",
    "    def prepare_data(self, train_df, test_df, train_embeddings, test_embeddings):\n",
    "        \"\"\"\n",
    "        Prepare data for SVM classification.\n",
    "        \"\"\"\n",
    "        # Get topic probabilities for both sets\n",
    "        _, train_probs = self.topic_model.transform(\n",
    "            train_df['combined_text'].tolist(),\n",
    "            train_embeddings\n",
    "        )\n",
    "        _, test_probs = self.topic_model.transform(\n",
    "            test_df['combined_text'].tolist(),\n",
    "            test_embeddings\n",
    "        )\n",
    "        \n",
    "        # Scale probabilities\n",
    "        X_train = self.scaler.fit_transform(train_probs)\n",
    "        X_test = self.scaler.transform(test_probs)\n",
    "        \n",
    "        # Get labels\n",
    "        y_train = train_df['Y'].values\n",
    "        y_test = test_df['Y'].values\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test\n",
    "    \n",
    "    def train_and_evaluate(self, train_df, test_df, kernel='rbf', C=2.0):\n",
    "        \"\"\"\n",
    "        Train SVM and evaluate performance.\n",
    "        \"\"\"\n",
    "        # Create embeddings\n",
    "        train_embeddings = self.process_and_embed_reports(train_df)\n",
    "        test_embeddings = self.process_and_embed_reports(test_df)\n",
    "        \n",
    "        # Fit topic model and prepare data\n",
    "        self.fit_transform_topics(train_df, train_embeddings)\n",
    "        X_train, X_test, y_train, y_test = self.prepare_data(\n",
    "            train_df, test_df, train_embeddings, test_embeddings\n",
    "        )\n",
    "        \n",
    "        # Train SVM\n",
    "        self.svm = SVC(kernel=kernel, C=C, probability=True, random_state=42)\n",
    "        self.svm.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = self.svm.predict(X_test)\n",
    "        y_pred_proba = self.svm.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        # Calculate metrics\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        metrics = {\n",
    "            'accuracy': accuracy_score(y_test, y_pred),\n",
    "            'auc': roc_auc_score(y_test, y_pred_proba),\n",
    "            'f1': f1_score(y_test, y_pred),\n",
    "            'sensitivity': tp / (tp + fn),\n",
    "            'specificity': tn / (tn + fp)\n",
    "        }\n",
    "        \n",
    "        # Store misclassified cases\n",
    "        self._store_misclassified(test_df, y_test, y_pred, y_pred_proba)\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    def _store_misclassified(self, test_df, y_true, y_pred, y_pred_proba):\n",
    "        \"\"\"\n",
    "        Store misclassified cases for analysis.\n",
    "        \"\"\"\n",
    "        misclassified_mask = y_true != y_pred\n",
    "        self.misclassified_cases = test_df[misclassified_mask].copy()\n",
    "        self.misclassified_cases['predicted_label'] = y_pred[misclassified_mask]\n",
    "        self.misclassified_cases['true_label'] = y_true[misclassified_mask]\n",
    "        self.misclassified_cases['prediction_probability'] = y_pred_proba[misclassified_mask]\n",
    "    \n",
    "    def save_model(self, model_name):\n",
    "        \"\"\"\n",
    "        Save the complete model including BERTopic and SVM.\n",
    "        \"\"\"\n",
    "        save_dir = self.save_path / model_name\n",
    "        save_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Save BERTopic model\n",
    "        self.topic_model.save(\n",
    "            str(save_dir / \"bertopic_model\"),\n",
    "            serialization=\"pytorch\",\n",
    "            save_ctfidf=True\n",
    "        )\n",
    "        \n",
    "        # Save SVM model\n",
    "        torch.save(self.svm, save_dir / \"svm_model.pt\")\n",
    "        \n",
    "        # Save scaler\n",
    "        torch.save(self.scaler, save_dir / \"scaler.pt\")\n",
    "        \n",
    "        # Save topic info\n",
    "        topic_info = self.topic_model.get_topic_info()\n",
    "        topic_info.to_csv(save_dir / \"topic_info.csv\")\n",
    "        \n",
    "    def load_model(self, model_name):\n",
    "        \"\"\"\n",
    "        Load a previously saved model.\n",
    "        \"\"\"\n",
    "        model_dir = self.save_path / model_name\n",
    "        \n",
    "        # Load BERTopic\n",
    "        self.topic_model = BERTopic.load(\n",
    "            str(model_dir / \"bertopic_model\")\n",
    "        )\n",
    "        \n",
    "        # Load SVM and scaler\n",
    "        self.svm = torch.load(model_dir / \"svm_model.pt\")\n",
    "        self.scaler = torch.load(model_dir / \"scaler.pt\")\n",
    "\n",
    "def run_classification_pipeline(train_df, test_df, pretrained_model_name, model_save_path):\n",
    "    \"\"\"\n",
    "    Run the complete classification pipeline.\n",
    "    \"\"\"\n",
    "    # Initialize classifier\n",
    "    classifier = IntegratedRadiologyClassifier(\n",
    "        pretrained_model_name,\n",
    "        save_path=model_save_path\n",
    "    )\n",
    "    \n",
    "    # Train and evaluate with different kernels\n",
    "    kernels = ['rbf', 'linear']\n",
    "    best_metrics = None\n",
    "    best_kernel = None\n",
    "    \n",
    "    for kernel in kernels:\n",
    "        print(f\"\\nTraining with {kernel} kernel:\")\n",
    "        metrics = classifier.train_and_evaluate(train_df, test_df, kernel=kernel)\n",
    "        \n",
    "        print(\"\\nModel Performance Metrics:\")\n",
    "        for metric, value in metrics.items():\n",
    "            print(f\"{metric}: {value:.4f}\")\n",
    "        \n",
    "        if best_metrics is None or metrics['auc'] > best_metrics['auc']:\n",
    "            best_metrics = metrics\n",
    "            best_kernel = kernel\n",
    "    \n",
    "    print(f\"\\nBest performing kernel: {best_kernel}\")\n",
    "    \n",
    "    # Save the best model\n",
    "    classifier.save_model(f\"radiology_classifier_{best_kernel}\")\n",
    "    \n",
    "    return classifier, best_metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
